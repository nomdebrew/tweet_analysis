{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nomdebrew/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nomdebrew/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pygal\n",
    "from pygal.style import Style\n",
    "from textblob import TextBlob\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "data = pd.read_csv(\"csv/tweets.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203430, 2)\n",
      "(25555, 4)\n",
      "(40403, 4)\n",
      "(57521, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "columns_to_use = ['created_str','text']\n",
    "data = data[columns_to_use]\n",
    "data = data.dropna(subset=['text'])\n",
    "\n",
    "#convert created_str to datetime and drop hour, min, sec\n",
    "data['created_str'] = pd.to_datetime(data['created_str'])\n",
    "data.created_str = data.created_str.map(lambda x: x.replace(day=1, hour=0, minute=0, second=0))\n",
    "\n",
    "\n",
    "clintonData = data[data['text'].str.contains('clinton|hillary', case=False)]\n",
    "trumpData = data[data['text'].str.contains('trump|donald', case=False)]\n",
    "bothData = data[data['text'].str.contains('clinton|hillary|trump|donald', case=False)]\n",
    "\n",
    "#add polarity and subjectivity columns to dataframes\n",
    "clintonData['polarity'] = clintonData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "clintonData['subjectivity'] = clintonData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "trumpData['polarity'] = trumpData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "trumpData['subjectivity'] = trumpData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "bothData['polarity'] = bothData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "bothData['subjectivity'] = bothData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "\n",
    "df_C1 = clintonData.groupby('created_str').mean()\n",
    "df_T1 = trumpData.groupby('created_str').mean()\n",
    "df_B1 = bothData.groupby('created_str').mean()\n",
    "\n",
    "print(data.shape)\n",
    "print(clintonData.shape)\n",
    "print(trumpData.shape)\n",
    "print(bothData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dates back into column instead of being an index\n",
    "df_C1.to_csv('csv/clinton_1.csv', sep=',')\n",
    "df_C1 = pd.read_csv('csv/clinton_1.csv')\n",
    "\n",
    "df_T1.to_csv('csv/trump_1.csv', sep=',')\n",
    "df_T1 = pd.read_csv('csv/trump_1.csv')\n",
    "\n",
    "df_B1.to_csv('csv/both_1.csv', sep=',')\n",
    "df_B1 = pd.read_csv('csv/both_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_style = Style(colors=('red','blue','purple'))\n",
    "date_chart = pygal.Line(x_label_rotation=60, fill=False, style=custom_style)\n",
    "date_chart.title = 'Polarity Over Time'\n",
    "date_chart.x_labels = df_C1['created_str']\n",
    "date_chart.add(\"trump\", df_T1['polarity'])\n",
    "date_chart.add(\"Clinton\", df_C1['polarity'])\n",
    "date_chart.add(\"Both\", df_B1['polarity'])\n",
    "date_chart.render_to_file('images/polarity_date.svg')\n",
    "\n",
    "date_chart = pygal.Line(x_label_rotation=60, fill=False, style=custom_style)\n",
    "date_chart.title = 'Subjectivity Over Time'\n",
    "date_chart.x_labels = df_C1['created_str']\n",
    "date_chart.add(\"trump\", df_T1['subjectivity'])\n",
    "date_chart.add(\"Clinton\", df_C1['subjectivity'])\n",
    "date_chart.add(\"Both\", df_B1['subjectivity'])\n",
    "date_chart.render_to_file('images/subjectivity_date.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_style = Style(colors=('red',))\n",
    "gauge = pygal.SolidGauge(inner_radius=0.70, style=custom_style, show_legend=False)\n",
    "percent_formatter = lambda x: '{:.10g}%'.format(x)\n",
    "gauge.title = 'trump'\n",
    "gauge.value_formatter = percent_formatter\n",
    "gauge.add('trump', [{'value': round(len(trumpData)/len(data)*100,1), 'max_value': 100}])\n",
    "gauge.render_to_file('images/t_guage.svg')\n",
    "\n",
    "custom_style = Style(colors=('blue',))\n",
    "gauge = pygal.SolidGauge(inner_radius=0.70, style=custom_style, show_legend=False)\n",
    "percent_formatter = lambda x: '{:.10g}%'.format(x)\n",
    "gauge.title = 'Clinton'\n",
    "gauge.value_formatter = percent_formatter\n",
    "gauge.add('Clinton', [{'value': round(len(clintonData)/len(data)*100,1), 'max_value': 100}])\n",
    "gauge.render_to_file('images/c_guage.svg')\n",
    "\n",
    "custom_style = Style(colors=('purple',))\n",
    "gauge = pygal.SolidGauge(inner_radius=0.70, style=custom_style, show_legend=False)\n",
    "percent_formatter = lambda x: '{:.10g}%'.format(x)\n",
    "gauge.title = 'Both'\n",
    "gauge.value_formatter = percent_formatter\n",
    "gauge.add('Both', [{'value': round(len(bothData)/len(data)*100,1), 'max_value': 100}])\n",
    "gauge.render_to_file('images/b_guage.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex dataframes\n",
    "clintonData = clintonData.reset_index(drop=True)\n",
    "trumpData = trumpData.reset_index(drop=True)\n",
    "bothData = bothData.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  polarity\n",
      "0      RT @NahBabyNah: Twitchy: Chuck Todd caught out...  0.000000\n",
      "12243  Wikileaks 13: Emails Prove #Obama Lied When He...  0.000000\n",
      "5445   #TopNews Obama turns focus to U.S. Congress as...  0.000000\n",
      "5446   RT @TRUMPMOVEMENTUS: Thank you  America! - aga...  0.000000\n",
      "5451   RT @sharronrenee26: #IStartCryingWhen @BernieS...  0.000000\n",
      "5452   RT @nansen: EXCLUSIVE: Clinton Aides Resisted ...  0.000000\n",
      "5453   RT @Tuniekc: #LEGACY\\n5 yrs since Gaddafi’s ki...  0.000000\n",
      "5454   Hillary just explained how Trump’s death would...  0.000000\n",
      "5456   RT @pmatas: Top Clinton Aide: Loss 'Most Devas...  0.000000\n",
      "5457   RT @ClintonCantBail: LA TIMES POLL: TRUMP 47.2...  0.000000\n",
      "5458   RT @FakeTonyAbbott1: Cowardice of the highest ...  0.000000\n",
      "5459   Rand Paul: Polls showing Clinton ahead are 'de...  0.000000\n",
      "5462   RT @jojokejohn: ALL TROLL HILLARY OR TRUMP  OO...  0.000000\n",
      "5463   RT @ZaibatsuNews: Yes, Deplorables, I'm Voting...  0.000000\n",
      "5465   RT @stephenstephan: BREAKING: Hillary Clinton ...  0.000000\n",
      "5470   RT @Patriot_MM: @HillaryClinton\\n\\n#hilLIARy i...  0.000000\n",
      "5471   RT @h8mpy: Hillary Clinton emails #ThingsYouca...  0.000000\n",
      "5473   Trump: #Clinton could shoot someone and not ge...  0.000000\n",
      "5474   #teapartynews #usa #america #americaproud #pea...  0.000000\n",
      "5478   RT @nobamanoway: Same @Reuters that told us Hi...  0.000000\n",
      "5479   RT @AtlantaBreaking: Clinton agrees to testify...  0.000000\n",
      "5481   Hillary Clinton Calls for a ‘National Service ...  0.000000\n",
      "5482   RT @LindaSuhler: DONALD J. TRUMP STATEMENT\\n#T...  0.000000\n",
      "5483   RT @LindaSuhler: You media loons who destroyed...  0.000000\n",
      "5484   RT @USAneedsTRUMP: @mic @HillaryClinton \\nhttp...  0.000000\n",
      "5485   RT @dixiefortrump: Hypocritical Liberal Left a...  0.000000\n",
      "5489   #Trump\\n„Clintons Leibwächter entwaffnen“ http...  0.000000\n",
      "5491   RT @TopDogNews: EXCLUSIVE: ARMS DEALER EXPOSES...  0.000000\n",
      "5494   Poll shows Hillary Clinton, Donald Trump tied ...  0.000000\n",
      "5495   RT @SantitaJ: Please RT! #FlintWaterCrisis #Fl...  0.000000\n",
      "...                                                  ...       ...\n",
      "16397  Media says voter fraud doesn't exist.. So what...  0.168182\n",
      "14028  DNC Live: Hillary Clinton returning praise she...  0.168182\n",
      "19371  RT @annie7589: #IGetDepressedWhen someone endo...  0.168182\n",
      "18184  RT @ThankYouDonald: Hillary Clinton running fo...  0.168182\n",
      "18028  RT @sherrie369: OBAMA BLAMES RUSSIA For Hillar...  0.168182\n",
      "14386  RT @derekdob: Bernstein: FBI Would Not Reopen ...  0.168182\n",
      "14541  RT @rightvoicenow: Hillary Clinton Leaves Real...  0.168182\n",
      "14820  RT @politifactlive: LIVE FACT-CHECK: Hillary C...  0.168182\n",
      "21185  RT @JaredWyand: Trump at Economic Club Of New ...  0.168182\n",
      "22809  RT @MidgardDragon: People mad at Jimmy Fallon ...  0.169444\n",
      "10804  RT @PolyPatriot: RT FUTURE OF AMERICAN WOMEN U...  0.170000\n",
      "12693  It's as tough as choosing between Trump and Hi...  0.170370\n",
      "9677   RT @Lrihendry: Hillary's new campaign bus! #Hi...  0.170455\n",
      "8875   RT @Pen_Air: BOOM! NEW POLL: 60% believe #Croo...  0.170455\n",
      "1471   RT @DanScavino: LIVE on #Periscope: #TrumpTrai...  0.170455\n",
      "18378  7th time this Week Bill Clinton gets called a ...  0.170455\n",
      "23840  RT @gamma_ray239: LIVE FOOTAGE of #TheDemocrat...  0.170455\n",
      "11378  RT @rolandsmartin: LIVE on #Periscope: Can Dem...  0.170455\n",
      "23596  RT @America_1st_: New nickname for rapist Bill...  0.170455\n",
      "19298  Hillary's New Campaign Logo from Ben Garrison!...  0.170455\n",
      "3157   RT @RealAlexJones: BUSTED! New Clinton Scandal...  0.170455\n",
      "24394  RT @VivaLaAmes: Breaking : Trump leads Clinton...  0.170455\n",
      "7092   RT @GaetaSusan: How did we get to this Nightma...  0.170455\n",
      "16630  BREAKING: Obama Just Caught Trying to Sabotage...  0.170455\n",
      "8110   RT @Loofie68msncom2: https://t.co/wHiUc7e6oW H...  0.170455\n",
      "4800   RT @JayS2629: New Poll From Pennsylvania shows...  0.170455\n",
      "15913  A look inside new Hillary's plane! #HackingHil...  0.170455\n",
      "4899   RT @shortman5427: WATCH – New Video Ad DECIMAT...  0.170455\n",
      "17222  RT @realDailyWire: New Yorkers to Hillary: Go ...  0.170455\n",
      "19     RT @cupcake4120: I live in Mich now. All the H...  0.170455\n",
      "\n",
      "[8651 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "clintonData = clintonData.sort_values(by=['polarity'])\n",
    "print(clintonData.loc[0:19,['text','polarity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  subjectivity\n",
      "0      RT @mcicero10: #BernieSanders #Trump people sh...           0.0\n",
      "31651  RT @ChristiChat: MT @ChristiChat: #WakeUpAmeri...           0.0\n",
      "15678  RT @SCLconservative: The State Controlled Medi...           0.0\n",
      "15676  RT @FreedomChild3: Seven Ways Obama Is Trying ...           0.0\n",
      "15675  RT @theglobaluniter: @realDonaldTrump \\n\\n💥 Wh...           0.0\n",
      "15673  RT @Thiru_0914: 🇺🇸Donald J. Trump Rally SATURD...           0.0\n",
      "15671  RT @Trump__Pence: VIDEO : Senator Tim Scott Pr...           0.0\n",
      "31655  RT @business: Bloomberg exclusive: Vladimir Pu...           0.0\n",
      "31650  RT @realDonaldTrump: Today in Florida, I pledg...           0.0\n",
      "31657  Man is trying to scale Trump Tower in NYC usin...           0.0\n",
      "31659  RT @GoForTimmer: #ItsUnacceptableTo Act like r...           0.0\n",
      "31661  .@ericbolling: \"Can you imagine the president-...           0.0\n",
      "31662  RT @TrueCOT: Team Hillary Gave GOP Establishme...           0.0\n",
      "31664  Driver uses cardboard Trump head in carpool la...           0.0\n",
      "15657  RT @goldengateblond: Dear Media: When Trump sa...           0.0\n",
      "15656  RT @blicqer: Media Need 12-Step Program for Do...           0.0\n",
      "15655  #TrumpCampaignSlogans Guinea-pig wigs for ever...           0.0\n",
      "15666  RT @JDiamond1: A Trump supporter just grabbed ...           0.0\n",
      "15681  RT @KlayVolk: Hameed Darweesh The Man Just Rel...           0.0\n",
      "15684  RT @CO2HOG: Gingrich: ‘Without one-sided assau...           0.0\n",
      "31649  RT @tedsirota: ACT UP At 30: Reinvigorated For...           0.0\n",
      "15706  RT @larryelder: \"HuffPo Writer Tossed from #CP...           0.0\n",
      "15705  Energized white supremacists cheer Trump conve...           0.0\n",
      "15704  RT @nia4_trump: In #RealTime One MAN Stands Ta...           0.0\n",
      "15701  RT @AmyMek: Unacceptable! @twitter permits @Be...           0.0\n",
      "15700  RT @michaelharrisdr: @maddow &amp; #Moran you ...           0.0\n",
      "15698  RT @NYTnickc: Trump courts Springsteen's Ameri...           0.0\n",
      "15697  HELP AMERICA #UseYourHead #CrookedHillary #MAG...           0.0\n",
      "31637  RT @MaxBoot: Is Trump sane? His denial of real...           0.0\n",
      "15695  Trump, Clinton to receive intel briefings http...           0.0\n",
      "...                                                  ...           ...\n",
      "40372  RT @Gamiliell: WATCH: Amal Clooney Just OWNED ...           0.0\n",
      "63     RT @BernieSanders: President Trump: Women aren...           0.0\n",
      "40358  RT @ipscone: Time to talk of charging FBT Come...           0.0\n",
      "61     #crookedcruz #TrumpIsRight #TrumpWillWin #Trum...           0.0\n",
      "40357  @HillaryClinton you're going to jail #HillaryF...           0.0\n",
      "91     RT @BeanieCannt: #POTUSLastTweet  \\r\\n 'A book...           0.0\n",
      "110    RT @FriendlyJMC: Thank Goodness America stood ...           0.0\n",
      "109    Donald Trump calls Hillary Clinton a bigot dur...           0.0\n",
      "108    Trump Hotels fined $50G for credit card hack w...           0.0\n",
      "107    Trump to speak at Phyllis Schlafly's funeral h...           0.0\n",
      "106    U.S. Nazi leader sees Trump as white nationali...           0.0\n",
      "40348  #SurvivalGuideToThanksgiving don't mention Tru...           0.0\n",
      "104    Trump campaign CEO didn't want daughters 'goin...           0.0\n",
      "40349  RT @DanaGeezus: #TrumpsFavoriteHeadline Obama ...           0.0\n",
      "40351  RT @CharlesMBlow: Poll: Hillary Clinton leads ...           0.0\n",
      "101    RT @Trump_Videos: have lost all respect for Ch...           0.0\n",
      "100    How would the tax plans of Hillary Clinton and...           0.0\n",
      "98     RT @bmaggiemay: Trump hired ex-CIA director Ja...           0.0\n",
      "40354  Hillary says Trump is the candidate of racists...           0.0\n",
      "94     RT @realDonaldTrump: I agree, @MMFlint- To all...           0.0\n",
      "40356  Republicans Stuck With Trump Despite Fears Tha...           0.0\n",
      "89     RT @foxnewsradio: Donald Trump reaches out to ...           0.0\n",
      "60     U.S. Rep. Marcia Fudge dismisses Donald Trump'...           0.0\n",
      "59     Who could be on the stump for Hillary Clinton ...           0.0\n",
      "58     RT @PoliticalHedge: Blaming Trump, Schwarzeneg...           0.0\n",
      "23     RT @MattaAbraham1: Donald Trump offers retired...           0.0\n",
      "40390  Donald Trump to campaign in Maryland https://t...           0.0\n",
      "21     RT @billsoltis: DON'T FORGET TONIGHT AT 9:30 E...           0.0\n",
      "40391  RT @Russell_941: Trump Donates to North Caroli...           0.0\n",
      "19     #MichelleObama addresses Melania Trump’s plagi...           0.0\n",
      "\n",
      "[13831 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "trumpData = trumpData.sort_values(by=['subjectivity'])\n",
    "print(trumpData.loc[0:19,['text','subjectivity']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Remove Stop Words From Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "custom_stopwords = ['RT','https','http','@']\n",
    "stop.extend(custom_stopwords)\n",
    "\n",
    "clintonData['without_stopwords'] = clintonData['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "trumpData['without_stopwords'] = trumpData['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "bothData['without_stopwords'] = bothData['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tokenize Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "clintonData['tokenized_sents'] = clintonData.apply(lambda row: nltk.word_tokenize(row['without_stopwords']), axis=1)\n",
    "trumpData['tokenized_sents'] = trumpData.apply(lambda row: nltk.word_tokenize(row['without_stopwords']), axis=1)\n",
    "bothData['tokenized_sents'] = bothData.apply(lambda row: nltk.word_tokenize(row['without_stopwords']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lemmatize Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "clintonData['text_lemmatized'] = clintonData.tokenized_sents.apply(lemmatize_text)\n",
    "trumpData['text_lemmatized'] = trumpData.tokenized_sents.apply(lemmatize_text)\n",
    "bothData['text_lemmatized'] = bothData.tokenized_sents.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_str</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>without_stopwords</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8237</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>RT @luvGodncountry: Wikileaks: Clinton Adviser...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@luvGodncountry: Wikileaks: Clinton Adviser Ta...</td>\n",
       "      <td>[@, luvGodncountry, :, Wikileaks, :, Clinton, ...</td>\n",
       "      <td>[@, luvGodncountry, :, Wikileaks, :, Clinton, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10990</th>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>RT @andersonDrLJA: #BillClinton #Obama #Hillar...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@andersonDrLJA: #BillClinton #Obama #Hillary A...</td>\n",
       "      <td>[@, andersonDrLJA, :, #, BillClinton, #, Obama...</td>\n",
       "      <td>[@, andersonDrLJA, :, #, BillClinton, #, Obama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19887</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>RT @venus58: Hey @ShepNewsTeam your show was A...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>@venus58: Hey @ShepNewsTeam show ALL CRAP 2day...</td>\n",
       "      <td>[@, venus58, :, Hey, @, ShepNewsTeam, show, AL...</td>\n",
       "      <td>[@, venus58, :, Hey, @, ShepNewsTeam, show, AL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>RT @Col_Connaughton: ASSANGE: CLINTON MEDIA 'E...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@Col_Connaughton: ASSANGE: CLINTON MEDIA 'EREC...</td>\n",
       "      <td>[@, Col_Connaughton, :, ASSANGE, :, CLINTON, M...</td>\n",
       "      <td>[@, Col_Connaughton, :, ASSANGE, :, CLINTON, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8562</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>Tennessee GOP\\n@TEN_GOP\\nTrump: \"Hillary Clint...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tennessee GOP @TEN_GOP Trump: \"Hillary Clinton...</td>\n",
       "      <td>[Tennessee, GOP, @, TEN_GOP, Trump, :, ``, Hil...</td>\n",
       "      <td>[Tennessee, GOP, @, TEN_GOP, Trump, :, ``, Hil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      created_str                                               text  \\\n",
       "8237   2016-10-01  RT @luvGodncountry: Wikileaks: Clinton Adviser...   \n",
       "10990  2016-06-01  RT @andersonDrLJA: #BillClinton #Obama #Hillar...   \n",
       "19887  2016-09-01  RT @venus58: Hey @ShepNewsTeam your show was A...   \n",
       "1049   2016-09-01  RT @Col_Connaughton: ASSANGE: CLINTON MEDIA 'E...   \n",
       "8562   2016-10-01  Tennessee GOP\\n@TEN_GOP\\nTrump: \"Hillary Clint...   \n",
       "\n",
       "       polarity  subjectivity  \\\n",
       "8237       -1.0           1.0   \n",
       "10990      -1.0           1.0   \n",
       "19887      -1.0           0.8   \n",
       "1049       -1.0           1.0   \n",
       "8562       -1.0           1.0   \n",
       "\n",
       "                                       without_stopwords  \\\n",
       "8237   @luvGodncountry: Wikileaks: Clinton Adviser Ta...   \n",
       "10990  @andersonDrLJA: #BillClinton #Obama #Hillary A...   \n",
       "19887  @venus58: Hey @ShepNewsTeam show ALL CRAP 2day...   \n",
       "1049   @Col_Connaughton: ASSANGE: CLINTON MEDIA 'EREC...   \n",
       "8562   Tennessee GOP @TEN_GOP Trump: \"Hillary Clinton...   \n",
       "\n",
       "                                         tokenized_sents  \\\n",
       "8237   [@, luvGodncountry, :, Wikileaks, :, Clinton, ...   \n",
       "10990  [@, andersonDrLJA, :, #, BillClinton, #, Obama...   \n",
       "19887  [@, venus58, :, Hey, @, ShepNewsTeam, show, AL...   \n",
       "1049   [@, Col_Connaughton, :, ASSANGE, :, CLINTON, M...   \n",
       "8562   [Tennessee, GOP, @, TEN_GOP, Trump, :, ``, Hil...   \n",
       "\n",
       "                                         text_lemmatized  \n",
       "8237   [@, luvGodncountry, :, Wikileaks, :, Clinton, ...  \n",
       "10990  [@, andersonDrLJA, :, #, BillClinton, #, Obama...  \n",
       "19887  [@, venus58, :, Hey, @, ShepNewsTeam, show, AL...  \n",
       "1049   [@, Col_Connaughton, :, ASSANGE, :, CLINTON, M...  \n",
       "8562   [Tennessee, GOP, @, TEN_GOP, Trump, :, ``, Hil...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clintonData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
