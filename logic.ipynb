{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nomdebrew/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nomdebrew/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pygal\n",
    "from pygal.style import Style\n",
    "from textblob import TextBlob\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "data = pd.read_csv(\"csv/tweets.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Drop columns except 'created_str' and 'text', separate data, and perform sentiment analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203430, 2)\n",
      "(25555, 4)\n",
      "(40403, 4)\n",
      "(57521, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "columns_to_use = ['created_str','text']\n",
    "data = data[columns_to_use]\n",
    "data = data.dropna(subset=['text'])\n",
    "\n",
    "#convert created_str to datetime and drop hour, min, sec\n",
    "data['created_str'] = pd.to_datetime(data['created_str'])\n",
    "data.created_str = data.created_str.map(lambda x: x.replace(day=1, hour=0, minute=0, second=0))\n",
    "\n",
    "\n",
    "clintonData = data[data['text'].str.contains('clinton|hillary', case=False)]\n",
    "trumpData = data[data['text'].str.contains('trump|donald', case=False)]\n",
    "bothData = data[data['text'].str.contains('clinton|hillary|trump|donald', case=False)]\n",
    "\n",
    "#add polarity and subjectivity columns to dataframes\n",
    "clintonData['polarity'] = clintonData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "clintonData['subjectivity'] = clintonData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "trumpData['polarity'] = trumpData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "trumpData['subjectivity'] = trumpData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "bothData['polarity'] = bothData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "bothData['subjectivity'] = bothData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "\n",
    "df_C1 = clintonData.groupby('created_str').mean()\n",
    "df_T1 = trumpData.groupby('created_str').mean()\n",
    "df_B1 = bothData.groupby('created_str').mean()\n",
    "\n",
    "print(data.shape)\n",
    "print(clintonData.shape)\n",
    "print(trumpData.shape)\n",
    "print(bothData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dates back into column instead of being an index\n",
    "df_C1.to_csv('csv/clinton_1.csv', sep=',')\n",
    "df_C1 = pd.read_csv('csv/clinton_1.csv')\n",
    "\n",
    "df_T1.to_csv('csv/trump_1.csv', sep=',')\n",
    "df_T1 = pd.read_csv('csv/trump_1.csv')\n",
    "\n",
    "df_B1.to_csv('csv/both_1.csv', sep=',')\n",
    "df_B1 = pd.read_csv('csv/both_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generate Graphs with Pygal before preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_style = Style(colors=('red','blue','purple'))\n",
    "date_chart = pygal.Line(x_label_rotation=60, fill=False, style=custom_style)\n",
    "date_chart.title = 'Polarity Over Time'\n",
    "date_chart.x_labels = df_C1['created_str']\n",
    "date_chart.add(\"trump\", df_T1['polarity'])\n",
    "date_chart.add(\"Clinton\", df_C1['polarity'])\n",
    "date_chart.add(\"Both\", df_B1['polarity'])\n",
    "date_chart.render_to_file('images/polarity_date.svg')\n",
    "\n",
    "date_chart = pygal.Line(x_label_rotation=60, fill=False, style=custom_style)\n",
    "date_chart.title = 'Subjectivity Over Time'\n",
    "date_chart.x_labels = df_C1['created_str']\n",
    "date_chart.add(\"trump\", df_T1['subjectivity'])\n",
    "date_chart.add(\"Clinton\", df_C1['subjectivity'])\n",
    "date_chart.add(\"Both\", df_B1['subjectivity'])\n",
    "date_chart.render_to_file('images/subjectivity_date.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_style = Style(colors=('red',))\n",
    "gauge = pygal.SolidGauge(inner_radius=0.70, style=custom_style, show_legend=False)\n",
    "percent_formatter = lambda x: '{:.10g}%'.format(x)\n",
    "gauge.title = 'trump'\n",
    "gauge.value_formatter = percent_formatter\n",
    "gauge.add('trump', [{'value': round(len(trumpData)/len(data)*100,1), 'max_value': 100}])\n",
    "gauge.render_to_file('images/t_guage.svg')\n",
    "\n",
    "custom_style = Style(colors=('blue',))\n",
    "gauge = pygal.SolidGauge(inner_radius=0.70, style=custom_style, show_legend=False)\n",
    "percent_formatter = lambda x: '{:.10g}%'.format(x)\n",
    "gauge.title = 'Clinton'\n",
    "gauge.value_formatter = percent_formatter\n",
    "gauge.add('Clinton', [{'value': round(len(clintonData)/len(data)*100,1), 'max_value': 100}])\n",
    "gauge.render_to_file('images/c_guage.svg')\n",
    "\n",
    "custom_style = Style(colors=('purple',))\n",
    "gauge = pygal.SolidGauge(inner_radius=0.70, style=custom_style, show_legend=False)\n",
    "percent_formatter = lambda x: '{:.10g}%'.format(x)\n",
    "gauge.title = 'Both'\n",
    "gauge.value_formatter = percent_formatter\n",
    "gauge.add('Both', [{'value': round(len(bothData)/len(data)*100,1), 'max_value': 100}])\n",
    "gauge.render_to_file('images/b_guage.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex dataframe\n",
    "bothData = bothData.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  polarity\n",
      "0   RT @luvGodncountry: Wikileaks: Clinton Adviser...      -1.0\n",
      "1   RT @andersonDrLJA: #BillClinton #Obama #Hillar...      -1.0\n",
      "2   RT @venus58: Hey @ShepNewsTeam your show was A...      -1.0\n",
      "3   RT @Col_Connaughton: ASSANGE: CLINTON MEDIA 'E...      -1.0\n",
      "4   Tennessee GOP\\n@TEN_GOP\\nTrump: \"Hillary Clint...      -1.0\n",
      "5   RT @HelloHello228: Terrible I'll bet that hurt...      -1.0\n",
      "6   RT @netwrkguy: @StopStopHillary @sluggoD54 Loo...      -1.0\n",
      "7   💣 BREAKING!!!!! 💣\\n\\n‘Calibration error’ chang...      -1.0\n",
      "8                  @HillaryClinton VETERANS HATE YOU!      -1.0\n",
      "9   RT @kevkid79: \"Clinton Camp Claims Media Was P...      -1.0\n",
      "10  Bernie campaign director endorses Trump, slams...      -1.0\n",
      "11  RT @Merry__Can: @HillaryClinton #democRATS are...      -1.0\n",
      "12  SHOCKING: Leaked photo of Hillary Clinton with...      -1.0\n",
      "13  Hillary Clinton protects serial rapist Bill Cl...      -1.0\n",
      "14  RT @bob_owens: If Trump is the worst candidate...      -1.0\n",
      "15  RT @randyshort: Moment Donald Trump Won The El...      -1.0\n",
      "16  RT @andersonDrLJA: #BillClinton #Obama #Hillar...      -1.0\n",
      "17  RT @abusedtaxpayer: Hillary's Worst Health Pro...      -1.0\n",
      "18  RT @andersonDrLJA: #BillClinton #Obama #Hillar...      -1.0\n",
      "19  RT @drapermark37: I PISS ON #LIBERALS! THEY WI...      -1.0\n"
     ]
    }
   ],
   "source": [
    "clintonData = clintonData.sort_values(by=['polarity'])\n",
    "clintonData = clintonData.reset_index(drop=True)\n",
    "print(clintonData.loc[0:19,['text','polarity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  subjectivity\n",
      "0   RT @mcicero10: #BernieSanders #Trump people sh...           0.0\n",
      "1   RT @ChristiChat: MT @ChristiChat: #WakeUpAmeri...           0.0\n",
      "2   RT @SCLconservative: The State Controlled Medi...           0.0\n",
      "3   RT @FreedomChild3: Seven Ways Obama Is Trying ...           0.0\n",
      "4   RT @theglobaluniter: @realDonaldTrump \\n\\n💥 Wh...           0.0\n",
      "5   RT @Thiru_0914: 🇺🇸Donald J. Trump Rally SATURD...           0.0\n",
      "6   RT @Trump__Pence: VIDEO : Senator Tim Scott Pr...           0.0\n",
      "7   RT @business: Bloomberg exclusive: Vladimir Pu...           0.0\n",
      "8   RT @realDonaldTrump: Today in Florida, I pledg...           0.0\n",
      "9   Man is trying to scale Trump Tower in NYC usin...           0.0\n",
      "10  RT @GoForTimmer: #ItsUnacceptableTo Act like r...           0.0\n",
      "11  .@ericbolling: \"Can you imagine the president-...           0.0\n",
      "12  RT @TrueCOT: Team Hillary Gave GOP Establishme...           0.0\n",
      "13  Driver uses cardboard Trump head in carpool la...           0.0\n",
      "14  RT @goldengateblond: Dear Media: When Trump sa...           0.0\n",
      "15  RT @blicqer: Media Need 12-Step Program for Do...           0.0\n",
      "16  #TrumpCampaignSlogans Guinea-pig wigs for ever...           0.0\n",
      "17  RT @JDiamond1: A Trump supporter just grabbed ...           0.0\n",
      "18  RT @KlayVolk: Hameed Darweesh The Man Just Rel...           0.0\n",
      "19  RT @CO2HOG: Gingrich: ‘Without one-sided assau...           0.0\n"
     ]
    }
   ],
   "source": [
    "trumpData = trumpData.sort_values(by=['subjectivity'])\n",
    "trumpData = trumpData.reset_index(drop=True)\n",
    "print(trumpData.loc[0:19,['text','subjectivity']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tokenize Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clintonData['tokenized_sents'] = clintonData.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "trumpData['tokenized_sents'] = trumpData.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "bothData['tokenized_sents'] = bothData.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lemmatize Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "clintonData['text_lemmatized'] = clintonData.tokenized_sents.apply(lemmatize_text)\n",
    "trumpData['text_lemmatized'] = trumpData.tokenized_sents.apply(lemmatize_text)\n",
    "bothData['text_lemmatized'] = bothData.tokenized_sents.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Remove Stop Words From Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "custom_stopwords = ['RT','https','http','@',':']\n",
    "stop.extend(custom_stopwords)\n",
    "\n",
    "clintonData['without_stopwords'] = clintonData.text_lemmatized.apply(lambda x: [item for item in x if item not in stop])\n",
    "trumpData['without_stopwords'] = trumpData.text_lemmatized.apply(lambda x: [item for item in x if item not in stop])\n",
    "bothData['without_stopwords'] = bothData.text_lemmatized.apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Join tokens back together</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clintonData['processed'] = clintonData.without_stopwords.apply(lambda x: ' '.join(word for word in x))\n",
    "trumpData['processed'] = trumpData.without_stopwords.apply(lambda x: ' '.join(word for word in x))\n",
    "bothData['processed'] = bothData.without_stopwords.apply(lambda x: ' '.join(word for word in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Processed Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0   RT @NahBabyNah: Twitchy: Chuck Todd caught out...   \n",
      "1   RT @mcicero10: #BernieSanders #Trump people sh...   \n",
      "2   RT @ItsJustJaynie: @HillaryClinton The undecid...   \n",
      "3   @NickTomaWBRE Hi, Nick! We're holding a \"Miner...   \n",
      "4   RT @HillaryClinton: This one's for you, Hillar...   \n",
      "5   RT @leonpui_: Hillary Clinton, Obama and the D...   \n",
      "6   #TrumpBecause #DonaldTrump will not be bought!...   \n",
      "7   RT @PrisonPlanet: Hillary's anti-Trump poster ...   \n",
      "8   RT @TrumpSuperPAC: #AfricanAmericans like @Jer...   \n",
      "9   RT @American_Woman4: #MAGA,#FEMININEAMERICA4TR...   \n",
      "10  RT @Conservatexian: News post: \"TWITTER Buries...   \n",
      "11  RT @1_Hoof_Hearted: @TuckerCarlson\\r\\n@JRubinB...   \n",
      "12  RT @babysgramma: @upayr Obama rules by exec or...   \n",
      "13  Trump appears to encourage gun owners to take ...   \n",
      "14  Obama on Trump winning: 'Anything's possible' ...   \n",
      "15  RT @stormynights10: #TrumpsFavoriteHeadline Tr...   \n",
      "16  RT @Grummz: CNN: \"we got played\"\\nTranslation:...   \n",
      "17  RT @BlastingNews: Trump sued for violating Con...   \n",
      "18  Vice President Joe Biden talks up Hillary Clin...   \n",
      "19  RT @Mr_Nielsen_5309: More proof that @HillaryC...   \n",
      "\n",
      "                                            processed  \n",
      "0   NahBabyNah Twitchy Chuck Todd caught shilling ...  \n",
      "1   mcicero10 # BernieSanders # Trump people rally...  \n",
      "2   ItsJustJaynie HillaryClinton The undecided vot...  \n",
      "3   NickTomaWBRE Hi , Nick ! We 're holding `` Min...  \n",
      "4   HillaryClinton This one 's , Hillary . //t.co/...  \n",
      "5   leonpui_ Hillary Clinton , Obama Democrats use...  \n",
      "6   # TrumpBecause # DonaldTrump bought ! He know ...  \n",
      "7   PrisonPlanet Hillary 's anti-Trump poster chil...  \n",
      "8   TrumpSuperPAC # AfricanAmericans like JermonMa...  \n",
      "9   American_Woman4 # MAGA , # FEMININEAMERICA4TRU...  \n",
      "10  Conservatexian News post `` TWITTER Buries 32 ...  \n",
      "11  1_Hoof_Hearted TuckerCarlson JRubinBlogger # B...  \n",
      "12  babysgramma upayr Obama rule exec order , wish...  \n",
      "13  Trump appears encourage gun owner take action ...  \n",
      "14  Obama Trump winning 'Anything 's possible ' # ...  \n",
      "15  stormynights10 # TrumpsFavoriteHeadline Trump ...  \n",
      "16  Grummz CNN `` got played '' Translation Trump ...  \n",
      "17  BlastingNews Trump sued violating Constitution...  \n",
      "18  Vice President Joe Biden talk Hillary Clinton ...  \n",
      "19  Mr_Nielsen_5309 More proof HillaryClinton & am...  \n"
     ]
    }
   ],
   "source": [
    "print(bothData.loc[0:19,['text','processed']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Perform sentiment analysis on data after preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add polarity and subjectivity columns to dataframes\n",
    "clintonData['polarity_2'] = clintonData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "clintonData['subjectivity_2'] = clintonData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "trumpData['polarity_2'] = trumpData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "trumpData['subjectivity_2'] = trumpData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "bothData['polarity_2'] = bothData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "bothData['subjectivity_2'] = bothData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "\n",
    "\n",
    "df_C2 = clintonData.groupby('created_str').mean()\n",
    "df_T2 = trumpData.groupby('created_str').mean()\n",
    "df_B2 = bothData.groupby('created_str').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dates back into column instead of being an index\n",
    "df_C2.to_csv('csv/clinton_2.csv', sep=',')\n",
    "df_C2 = pd.read_csv('csv/clinton_2.csv')\n",
    "\n",
    "df_T2.to_csv('csv/trump_2.csv', sep=',')\n",
    "df_T2 = pd.read_csv('csv/trump_2.csv')\n",
    "\n",
    "df_B2.to_csv('csv/both_2.csv', sep=',')\n",
    "df_B2 = pd.read_csv('csv/both_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generate graphs with Pygal after preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_style = Style(colors=('red','blue','purple'))\n",
    "date_chart = pygal.Line(x_label_rotation=60, fill=False, style=custom_style)\n",
    "date_chart.title = 'Polarity Over Time'\n",
    "date_chart.x_labels = df_C2['created_str']\n",
    "date_chart.add(\"trump\", df_T2['polarity_2'])\n",
    "date_chart.add(\"Clinton\", df_C2['polarity_2'])\n",
    "date_chart.add(\"Both\", df_B2['polarity_2'])\n",
    "date_chart.render_to_file('images/polarity_date_processed.svg')\n",
    "\n",
    "date_chart = pygal.Line(x_label_rotation=60, fill=False, style=custom_style)\n",
    "date_chart.title = 'Subjectivity Over Time'\n",
    "date_chart.x_labels = df_C2['created_str']\n",
    "date_chart.add(\"trump\", df_T2['subjectivity_2'])\n",
    "date_chart.add(\"Clinton\", df_C2['subjectivity_2'])\n",
    "date_chart.add(\"Both\", df_B2['subjectivity_2'])\n",
    "date_chart.render_to_file('images/subjectivity_date_processed.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Processed dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_str</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>without_stopwords</th>\n",
       "      <th>processed</th>\n",
       "      <th>polarity_2</th>\n",
       "      <th>subjectivity_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>RT @NahBabyNah: Twitchy: Chuck Todd caught out...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[RT, @, NahBabyNah, :, Twitchy, :, Chuck, Todd...</td>\n",
       "      <td>[RT, @, NahBabyNah, :, Twitchy, :, Chuck, Todd...</td>\n",
       "      <td>[NahBabyNah, Twitchy, Chuck, Todd, caught, shi...</td>\n",
       "      <td>NahBabyNah Twitchy Chuck Todd caught shilling ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>RT @mcicero10: #BernieSanders #Trump people sh...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[RT, @, mcicero10, :, #, BernieSanders, #, Tru...</td>\n",
       "      <td>[RT, @, mcicero10, :, #, BernieSanders, #, Tru...</td>\n",
       "      <td>[mcicero10, #, BernieSanders, #, Trump, people...</td>\n",
       "      <td>mcicero10 # BernieSanders # Trump people rally...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>RT @ItsJustJaynie: @HillaryClinton The undecid...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[RT, @, ItsJustJaynie, :, @, HillaryClinton, T...</td>\n",
       "      <td>[RT, @, ItsJustJaynie, :, @, HillaryClinton, T...</td>\n",
       "      <td>[ItsJustJaynie, HillaryClinton, The, undecided...</td>\n",
       "      <td>ItsJustJaynie HillaryClinton The undecided vot...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>@NickTomaWBRE Hi, Nick! We're holding a \"Miner...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[@, NickTomaWBRE, Hi, ,, Nick, !, We, 're, hol...</td>\n",
       "      <td>[@, NickTomaWBRE, Hi, ,, Nick, !, We, 're, hol...</td>\n",
       "      <td>[NickTomaWBRE, Hi, ,, Nick, !, We, 're, holdin...</td>\n",
       "      <td>NickTomaWBRE Hi , Nick ! We 're holding `` Min...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>RT @HillaryClinton: This one's for you, Hillar...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[RT, @, HillaryClinton, :, This, one, 's, for,...</td>\n",
       "      <td>[RT, @, HillaryClinton, :, This, one, 's, for,...</td>\n",
       "      <td>[HillaryClinton, This, one, 's, ,, Hillary, .,...</td>\n",
       "      <td>HillaryClinton This one 's , Hillary . //t.co/...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>RT @leonpui_: Hillary Clinton, Obama and the D...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>[RT, @, leonpui_, :, Hillary, Clinton, ,, Obam...</td>\n",
       "      <td>[RT, @, leonpui_, :, Hillary, Clinton, ,, Obam...</td>\n",
       "      <td>[leonpui_, Hillary, Clinton, ,, Obama, Democra...</td>\n",
       "      <td>leonpui_ Hillary Clinton , Obama Democrats use...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>#TrumpBecause #DonaldTrump will not be bought!...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>[#, TrumpBecause, #, DonaldTrump, will, not, b...</td>\n",
       "      <td>[#, TrumpBecause, #, DonaldTrump, will, not, b...</td>\n",
       "      <td>[#, TrumpBecause, #, DonaldTrump, bought, !, H...</td>\n",
       "      <td># TrumpBecause # DonaldTrump bought ! He know ...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>RT @PrisonPlanet: Hillary's anti-Trump poster ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[RT, @, PrisonPlanet, :, Hillary, 's, anti-Tru...</td>\n",
       "      <td>[RT, @, PrisonPlanet, :, Hillary, 's, anti-Tru...</td>\n",
       "      <td>[PrisonPlanet, Hillary, 's, anti-Trump, poster...</td>\n",
       "      <td>PrisonPlanet Hillary 's anti-Trump poster chil...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>RT @TrumpSuperPAC: #AfricanAmericans like @Jer...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[RT, @, TrumpSuperPAC, :, #, AfricanAmericans,...</td>\n",
       "      <td>[RT, @, TrumpSuperPAC, :, #, AfricanAmericans,...</td>\n",
       "      <td>[TrumpSuperPAC, #, AfricanAmericans, like, Jer...</td>\n",
       "      <td>TrumpSuperPAC # AfricanAmericans like JermonMa...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>RT @American_Woman4: #MAGA,#FEMININEAMERICA4TR...</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>[RT, @, American_Woman4, :, #, MAGA, ,, #, FEM...</td>\n",
       "      <td>[RT, @, American_Woman4, :, #, MAGA, ,, #, FEM...</td>\n",
       "      <td>[American_Woman4, #, MAGA, ,, #, FEMININEAMERI...</td>\n",
       "      <td>American_Woman4 # MAGA , # FEMININEAMERICA4TRU...</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>RT @Conservatexian: News post: \"TWITTER Buries...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[RT, @, Conservatexian, :, News, post, :, ``, ...</td>\n",
       "      <td>[RT, @, Conservatexian, :, News, post, :, ``, ...</td>\n",
       "      <td>[Conservatexian, News, post, ``, TWITTER, Buri...</td>\n",
       "      <td>Conservatexian News post `` TWITTER Buries 32 ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>RT @1_Hoof_Hearted: @TuckerCarlson\\r\\n@JRubinB...</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>[RT, @, 1_Hoof_Hearted, :, @, TuckerCarlson, @...</td>\n",
       "      <td>[RT, @, 1_Hoof_Hearted, :, @, TuckerCarlson, @...</td>\n",
       "      <td>[1_Hoof_Hearted, TuckerCarlson, JRubinBlogger,...</td>\n",
       "      <td>1_Hoof_Hearted TuckerCarlson JRubinBlogger # B...</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>RT @babysgramma: @upayr Obama rules by exec or...</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>[RT, @, babysgramma, :, @, upayr, Obama, rules...</td>\n",
       "      <td>[RT, @, babysgramma, :, @, upayr, Obama, rule,...</td>\n",
       "      <td>[babysgramma, upayr, Obama, rule, exec, order,...</td>\n",
       "      <td>babysgramma upayr Obama rule exec order , wish...</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>Trump appears to encourage gun owners to take ...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>[Trump, appears, to, encourage, gun, owners, t...</td>\n",
       "      <td>[Trump, appears, to, encourage, gun, owner, to...</td>\n",
       "      <td>[Trump, appears, encourage, gun, owner, take, ...</td>\n",
       "      <td>Trump appears encourage gun owner take action ...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Obama on Trump winning: 'Anything's possible' ...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>[Obama, on, Trump, winning, :, 'Anything, 's, ...</td>\n",
       "      <td>[Obama, on, Trump, winning, :, 'Anything, 's, ...</td>\n",
       "      <td>[Obama, Trump, winning, 'Anything, 's, possibl...</td>\n",
       "      <td>Obama Trump winning 'Anything 's possible ' # ...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>RT @stormynights10: #TrumpsFavoriteHeadline Tr...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[RT, @, stormynights10, :, #, TrumpsFavoriteHe...</td>\n",
       "      <td>[RT, @, stormynights10, :, #, TrumpsFavoriteHe...</td>\n",
       "      <td>[stormynights10, #, TrumpsFavoriteHeadline, Tr...</td>\n",
       "      <td>stormynights10 # TrumpsFavoriteHeadline Trump ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>RT @Grummz: CNN: \"we got played\"\\nTranslation:...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[RT, @, Grummz, :, CNN, :, ``, we, got, played...</td>\n",
       "      <td>[RT, @, Grummz, :, CNN, :, ``, we, got, played...</td>\n",
       "      <td>[Grummz, CNN, ``, got, played, '', Translation...</td>\n",
       "      <td>Grummz CNN `` got played '' Translation Trump ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>RT @BlastingNews: Trump sued for violating Con...</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>[RT, @, BlastingNews, :, Trump, sued, for, vio...</td>\n",
       "      <td>[RT, @, BlastingNews, :, Trump, sued, for, vio...</td>\n",
       "      <td>[BlastingNews, Trump, sued, violating, Constit...</td>\n",
       "      <td>BlastingNews Trump sued violating Constitution...</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>Vice President Joe Biden talks up Hillary Clin...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[Vice, President, Joe, Biden, talks, up, Hilla...</td>\n",
       "      <td>[Vice, President, Joe, Biden, talk, up, Hillar...</td>\n",
       "      <td>[Vice, President, Joe, Biden, talk, Hillary, C...</td>\n",
       "      <td>Vice President Joe Biden talk Hillary Clinton ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>RT @Mr_Nielsen_5309: More proof that @HillaryC...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>[RT, @, Mr_Nielsen_5309, :, More, proof, that,...</td>\n",
       "      <td>[RT, @, Mr_Nielsen_5309, :, More, proof, that,...</td>\n",
       "      <td>[Mr_Nielsen_5309, More, proof, HillaryClinton,...</td>\n",
       "      <td>Mr_Nielsen_5309 More proof HillaryClinton &amp; am...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_str                                               text  polarity  \\\n",
       "0   2016-09-01  RT @NahBabyNah: Twitchy: Chuck Todd caught out...  0.000000   \n",
       "1   2016-04-01  RT @mcicero10: #BernieSanders #Trump people sh...  0.000000   \n",
       "2   2016-10-01  RT @ItsJustJaynie: @HillaryClinton The undecid...  0.000000   \n",
       "3   2016-10-01  @NickTomaWBRE Hi, Nick! We're holding a \"Miner...  0.250000   \n",
       "4   2016-11-01  RT @HillaryClinton: This one's for you, Hillar...  0.000000   \n",
       "5   2016-09-01  RT @leonpui_: Hillary Clinton, Obama and the D...  0.250000   \n",
       "6   2015-08-01  #TrumpBecause #DonaldTrump will not be bought!...  0.000000   \n",
       "7   2016-09-01  RT @PrisonPlanet: Hillary's anti-Trump poster ...  0.000000   \n",
       "8   2016-11-01  RT @TrumpSuperPAC: #AfricanAmericans like @Jer...  0.000000   \n",
       "9   2016-09-01  RT @American_Woman4: #MAGA,#FEMININEAMERICA4TR...  0.575000   \n",
       "10  2016-10-01  RT @Conservatexian: News post: \"TWITTER Buries...  0.000000   \n",
       "11  2016-12-01  RT @1_Hoof_Hearted: @TuckerCarlson\\r\\n@JRubinB... -0.083333   \n",
       "12  2017-01-01  RT @babysgramma: @upayr Obama rules by exec or... -0.033333   \n",
       "13  2016-08-01  Trump appears to encourage gun owners to take ...  0.100000   \n",
       "14  2016-07-01  Obama on Trump winning: 'Anything's possible' ...  0.250000   \n",
       "15  2016-08-01  RT @stormynights10: #TrumpsFavoriteHeadline Tr...  0.000000   \n",
       "16  2016-09-01  RT @Grummz: CNN: \"we got played\"\\nTranslation:...  0.000000   \n",
       "17  2017-01-01  RT @BlastingNews: Trump sued for violating Con... -0.062500   \n",
       "18  2016-09-01  Vice President Joe Biden talks up Hillary Clin...  0.000000   \n",
       "19  2016-09-01  RT @Mr_Nielsen_5309: More proof that @HillaryC...  0.250000   \n",
       "\n",
       "    subjectivity                                    tokenized_sents  \\\n",
       "0       0.000000  [RT, @, NahBabyNah, :, Twitchy, :, Chuck, Todd...   \n",
       "1       0.000000  [RT, @, mcicero10, :, #, BernieSanders, #, Tru...   \n",
       "2       0.000000  [RT, @, ItsJustJaynie, :, @, HillaryClinton, T...   \n",
       "3       0.500000  [@, NickTomaWBRE, Hi, ,, Nick, !, We, 're, hol...   \n",
       "4       0.000000  [RT, @, HillaryClinton, :, This, one, 's, for,...   \n",
       "5       0.300000  [RT, @, leonpui_, :, Hillary, Clinton, ,, Obam...   \n",
       "6       0.100000  [#, TrumpBecause, #, DonaldTrump, will, not, b...   \n",
       "7       0.000000  [RT, @, PrisonPlanet, :, Hillary, 's, anti-Tru...   \n",
       "8       0.500000  [RT, @, TrumpSuperPAC, :, #, AfricanAmericans,...   \n",
       "9       0.825000  [RT, @, American_Woman4, :, #, MAGA, ,, #, FEM...   \n",
       "10      0.000000  [RT, @, Conservatexian, :, News, post, :, ``, ...   \n",
       "11      0.083333  [RT, @, 1_Hoof_Hearted, :, @, TuckerCarlson, @...   \n",
       "12      0.533333  [RT, @, babysgramma, :, @, upayr, Obama, rules...   \n",
       "13      0.100000  [Trump, appears, to, encourage, gun, owners, t...   \n",
       "14      0.875000  [Obama, on, Trump, winning, :, 'Anything, 's, ...   \n",
       "15      0.000000  [RT, @, stormynights10, :, #, TrumpsFavoriteHe...   \n",
       "16      0.000000  [RT, @, Grummz, :, CNN, :, ``, we, got, played...   \n",
       "17      0.062500  [RT, @, BlastingNews, :, Trump, sued, for, vio...   \n",
       "18      0.000000  [Vice, President, Joe, Biden, talks, up, Hilla...   \n",
       "19      0.250000  [RT, @, Mr_Nielsen_5309, :, More, proof, that,...   \n",
       "\n",
       "                                      text_lemmatized  \\\n",
       "0   [RT, @, NahBabyNah, :, Twitchy, :, Chuck, Todd...   \n",
       "1   [RT, @, mcicero10, :, #, BernieSanders, #, Tru...   \n",
       "2   [RT, @, ItsJustJaynie, :, @, HillaryClinton, T...   \n",
       "3   [@, NickTomaWBRE, Hi, ,, Nick, !, We, 're, hol...   \n",
       "4   [RT, @, HillaryClinton, :, This, one, 's, for,...   \n",
       "5   [RT, @, leonpui_, :, Hillary, Clinton, ,, Obam...   \n",
       "6   [#, TrumpBecause, #, DonaldTrump, will, not, b...   \n",
       "7   [RT, @, PrisonPlanet, :, Hillary, 's, anti-Tru...   \n",
       "8   [RT, @, TrumpSuperPAC, :, #, AfricanAmericans,...   \n",
       "9   [RT, @, American_Woman4, :, #, MAGA, ,, #, FEM...   \n",
       "10  [RT, @, Conservatexian, :, News, post, :, ``, ...   \n",
       "11  [RT, @, 1_Hoof_Hearted, :, @, TuckerCarlson, @...   \n",
       "12  [RT, @, babysgramma, :, @, upayr, Obama, rule,...   \n",
       "13  [Trump, appears, to, encourage, gun, owner, to...   \n",
       "14  [Obama, on, Trump, winning, :, 'Anything, 's, ...   \n",
       "15  [RT, @, stormynights10, :, #, TrumpsFavoriteHe...   \n",
       "16  [RT, @, Grummz, :, CNN, :, ``, we, got, played...   \n",
       "17  [RT, @, BlastingNews, :, Trump, sued, for, vio...   \n",
       "18  [Vice, President, Joe, Biden, talk, up, Hillar...   \n",
       "19  [RT, @, Mr_Nielsen_5309, :, More, proof, that,...   \n",
       "\n",
       "                                    without_stopwords  \\\n",
       "0   [NahBabyNah, Twitchy, Chuck, Todd, caught, shi...   \n",
       "1   [mcicero10, #, BernieSanders, #, Trump, people...   \n",
       "2   [ItsJustJaynie, HillaryClinton, The, undecided...   \n",
       "3   [NickTomaWBRE, Hi, ,, Nick, !, We, 're, holdin...   \n",
       "4   [HillaryClinton, This, one, 's, ,, Hillary, .,...   \n",
       "5   [leonpui_, Hillary, Clinton, ,, Obama, Democra...   \n",
       "6   [#, TrumpBecause, #, DonaldTrump, bought, !, H...   \n",
       "7   [PrisonPlanet, Hillary, 's, anti-Trump, poster...   \n",
       "8   [TrumpSuperPAC, #, AfricanAmericans, like, Jer...   \n",
       "9   [American_Woman4, #, MAGA, ,, #, FEMININEAMERI...   \n",
       "10  [Conservatexian, News, post, ``, TWITTER, Buri...   \n",
       "11  [1_Hoof_Hearted, TuckerCarlson, JRubinBlogger,...   \n",
       "12  [babysgramma, upayr, Obama, rule, exec, order,...   \n",
       "13  [Trump, appears, encourage, gun, owner, take, ...   \n",
       "14  [Obama, Trump, winning, 'Anything, 's, possibl...   \n",
       "15  [stormynights10, #, TrumpsFavoriteHeadline, Tr...   \n",
       "16  [Grummz, CNN, ``, got, played, '', Translation...   \n",
       "17  [BlastingNews, Trump, sued, violating, Constit...   \n",
       "18  [Vice, President, Joe, Biden, talk, Hillary, C...   \n",
       "19  [Mr_Nielsen_5309, More, proof, HillaryClinton,...   \n",
       "\n",
       "                                            processed  polarity_2  \\\n",
       "0   NahBabyNah Twitchy Chuck Todd caught shilling ...    0.000000   \n",
       "1   mcicero10 # BernieSanders # Trump people rally...    0.000000   \n",
       "2   ItsJustJaynie HillaryClinton The undecided vot...    0.000000   \n",
       "3   NickTomaWBRE Hi , Nick ! We 're holding `` Min...    0.250000   \n",
       "4   HillaryClinton This one 's , Hillary . //t.co/...    0.000000   \n",
       "5   leonpui_ Hillary Clinton , Obama Democrats use...    0.250000   \n",
       "6   # TrumpBecause # DonaldTrump bought ! He know ...   -0.200000   \n",
       "7   PrisonPlanet Hillary 's anti-Trump poster chil...    0.000000   \n",
       "8   TrumpSuperPAC # AfricanAmericans like JermonMa...    0.000000   \n",
       "9   American_Woman4 # MAGA , # FEMININEAMERICA4TRU...    0.575000   \n",
       "10  Conservatexian News post `` TWITTER Buries 32 ...    0.000000   \n",
       "11  1_Hoof_Hearted TuckerCarlson JRubinBlogger # B...   -0.083333   \n",
       "12  babysgramma upayr Obama rule exec order , wish...   -0.033333   \n",
       "13  Trump appears encourage gun owner take action ...    0.100000   \n",
       "14  Obama Trump winning 'Anything 's possible ' # ...    0.250000   \n",
       "15  stormynights10 # TrumpsFavoriteHeadline Trump ...    0.000000   \n",
       "16  Grummz CNN `` got played '' Translation Trump ...    0.000000   \n",
       "17  BlastingNews Trump sued violating Constitution...   -0.062500   \n",
       "18  Vice President Joe Biden talk Hillary Clinton ...    0.000000   \n",
       "19  Mr_Nielsen_5309 More proof HillaryClinton & am...    0.250000   \n",
       "\n",
       "    subjectivity_2  \n",
       "0         0.000000  \n",
       "1         0.000000  \n",
       "2         0.000000  \n",
       "3         0.500000  \n",
       "4         0.000000  \n",
       "5         0.300000  \n",
       "6         0.250000  \n",
       "7         0.000000  \n",
       "8         0.500000  \n",
       "9         0.825000  \n",
       "10        0.000000  \n",
       "11        0.083333  \n",
       "12        0.533333  \n",
       "13        0.100000  \n",
       "14        0.875000  \n",
       "15        0.000000  \n",
       "16        0.000000  \n",
       "17        0.062500  \n",
       "18        0.000000  \n",
       "19        0.250000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bothData.loc[0:19,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
