{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nomdebrew/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nomdebrew/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pygal\n",
    "from pygal.style import Style\n",
    "from textblob import TextBlob\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "data = pd.read_csv(\"csv/tweets.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203430, 2)\n",
      "(25555, 4)\n",
      "(40403, 4)\n",
      "(57521, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomdebrew/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "columns_to_use = ['created_str','text']\n",
    "data = data[columns_to_use]\n",
    "data = data.dropna(subset=['text'])\n",
    "\n",
    "#convert created_str to datetime and drop hour, min, sec\n",
    "data['created_str'] = pd.to_datetime(data['created_str'])\n",
    "data.created_str = data.created_str.map(lambda x: x.replace(day=1, hour=0, minute=0, second=0))\n",
    "\n",
    "\n",
    "clintonData = data[data['text'].str.contains('clinton|hillary', case=False)]\n",
    "trumpData = data[data['text'].str.contains('trump|donald', case=False)]\n",
    "bothData = data[data['text'].str.contains('clinton|hillary|trump|donald', case=False)]\n",
    "\n",
    "#add polarity and subjectivity columns to dataframes\n",
    "clintonData['polarity'] = clintonData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "clintonData['subjectivity'] = clintonData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "trumpData['polarity'] = trumpData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "trumpData['subjectivity'] = trumpData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "bothData['polarity'] = bothData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "bothData['subjectivity'] = bothData['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "\n",
    "df_C1 = clintonData.groupby('created_str').mean()\n",
    "df_T1 = trumpData.groupby('created_str').mean()\n",
    "df_B1 = bothData.groupby('created_str').mean()\n",
    "\n",
    "print(data.shape)\n",
    "print(clintonData.shape)\n",
    "print(trumpData.shape)\n",
    "print(bothData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dates back into column instead of being an index\n",
    "df_C1.to_csv('csv/clinton_1.csv', sep=',')\n",
    "df_C1 = pd.read_csv('csv/clinton_1.csv')\n",
    "\n",
    "df_T1.to_csv('csv/trump_1.csv', sep=',')\n",
    "df_T1 = pd.read_csv('csv/trump_1.csv')\n",
    "\n",
    "df_B1.to_csv('csv/both_1.csv', sep=',')\n",
    "df_B1 = pd.read_csv('csv/both_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_style = Style(colors=('red','blue','purple'))\n",
    "date_chart = pygal.Line(x_label_rotation=60, fill=False, style=custom_style)\n",
    "date_chart.title = 'Polarity Over Time'\n",
    "date_chart.x_labels = df_C1['created_str']\n",
    "date_chart.add(\"trump\", df_T1['polarity'])\n",
    "date_chart.add(\"Clinton\", df_C1['polarity'])\n",
    "date_chart.add(\"Both\", df_B1['polarity'])\n",
    "date_chart.render_to_file('images/polarity_date.svg')\n",
    "\n",
    "date_chart = pygal.Line(x_label_rotation=60, fill=False, style=custom_style)\n",
    "date_chart.title = 'Subjectivity Over Time'\n",
    "date_chart.x_labels = df_C1['created_str']\n",
    "date_chart.add(\"trump\", df_T1['subjectivity'])\n",
    "date_chart.add(\"Clinton\", df_C1['subjectivity'])\n",
    "date_chart.add(\"Both\", df_B1['subjectivity'])\n",
    "date_chart.render_to_file('images/subjectivity_date.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_style = Style(colors=('red',))\n",
    "gauge = pygal.SolidGauge(inner_radius=0.70, style=custom_style, show_legend=False)\n",
    "percent_formatter = lambda x: '{:.10g}%'.format(x)\n",
    "gauge.title = 'trump'\n",
    "gauge.value_formatter = percent_formatter\n",
    "gauge.add('trump', [{'value': round(len(trumpData)/len(data)*100,1), 'max_value': 100}])\n",
    "gauge.render_to_file('images/t_guage.svg')\n",
    "\n",
    "custom_style = Style(colors=('blue',))\n",
    "gauge = pygal.SolidGauge(inner_radius=0.70, style=custom_style, show_legend=False)\n",
    "percent_formatter = lambda x: '{:.10g}%'.format(x)\n",
    "gauge.title = 'Clinton'\n",
    "gauge.value_formatter = percent_formatter\n",
    "gauge.add('Clinton', [{'value': round(len(clintonData)/len(data)*100,1), 'max_value': 100}])\n",
    "gauge.render_to_file('images/c_guage.svg')\n",
    "\n",
    "custom_style = Style(colors=('purple',))\n",
    "gauge = pygal.SolidGauge(inner_radius=0.70, style=custom_style, show_legend=False)\n",
    "percent_formatter = lambda x: '{:.10g}%'.format(x)\n",
    "gauge.title = 'Both'\n",
    "gauge.value_formatter = percent_formatter\n",
    "gauge.add('Both', [{'value': round(len(bothData)/len(data)*100,1), 'max_value': 100}])\n",
    "gauge.render_to_file('images/b_guage.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindex dataframe\n",
    "bothData = bothData.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  polarity\n",
      "0   RT @luvGodncountry: Wikileaks: Clinton Adviser...      -1.0\n",
      "1   RT @VivaLaAmes: Holy CRAP, HILLARY HAS LOST IT...      -1.0\n",
      "2   RT @amborin: We must ensure that Hillary is no...      -1.0\n",
      "3   Clinton says Trump has been ‘degrading, insult...      -1.0\n",
      "4   RT @ElianaBenador: Exclusive — Trumpocrats Dem...      -1.0\n",
      "5   RT @JaredWyand: You are disgusting @HillaryCli...      -1.0\n",
      "6   RT @1Kimsey: @Crimsonmile @RichardGrenell @tam...      -1.0\n",
      "7   RT @pmbasse: Team Hillary Gave GOP Establishme...      -1.0\n",
      "8   RT @Harlan: Hillary is running a nasty, divisi...      -1.0\n",
      "9   RT @OzzeeLady: BREAKING: Federal Judge Gives H...      -1.0\n",
      "10  RT @LindaSuhler: But TRUMP is unfit?\\r\\nFrom t...      -1.0\n",
      "11  RT @ajenable: Embrace the power of and, my fri...      -1.0\n",
      "12  RT @trumpology: It's outrageous. They can keep...      -1.0\n",
      "13  RT @LouDobbs: Irony, Anyone? \"Sometimes Bill A...      -1.0\n",
      "14  RT @jenncox24: @RacySicilian @magnifier661 @Hi...      -1.0\n",
      "15  RT @NolteNC: Trump once and for all ends the B...      -1.0\n",
      "16  RT @lesliermyers: GOP created Trump with the d...      -1.0\n",
      "17  RT @dsrtime: What in the world!!  SHOCKING !!!...      -1.0\n",
      "18  RT @iKaitg16: SHOCKING !!! PROOF That Hillary ...      -1.0\n",
      "19  RT @LouDobbs: LATimes poll @realDonaldTrump Up...      -1.0\n"
     ]
    }
   ],
   "source": [
    "clintonData = clintonData.sort_values(by=['polarity'])\n",
    "clintonData = clintonData.reset_index(drop=True)\n",
    "print(clintonData.loc[0:19,['text','polarity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  subjectivity\n",
      "0   RT @mcicero10: #BernieSanders #Trump people sh...           0.0\n",
      "1   RT @Stonewall_77: Rewards For Services Rendere...           0.0\n",
      "2   RT @myGianLuca: RT @hillaryclinton @billclinto...           0.0\n",
      "3   RT @ForecasterEnten: Trump 46, Cruz 31, Rubio ...           0.0\n",
      "4   RT @TrivWorks: • Trump\\r\\n• Celebrity Deaths \\...           0.0\n",
      "5   RT @micafarha: @LeahR77 @Braveheart_USA @dreww...           0.0\n",
      "6   RT @realDailyWire: Ep. 220 - Trump Saved Jobs!...           0.0\n",
      "7   RT @Born_To_DYE: #TrumpsFavoriteHeadline Putin...           0.0\n",
      "8   RT @darleneturner53: For Trump to release his ...           0.0\n",
      "9   Trump Jr. likens Syrian refugees to Skittles h...           0.0\n",
      "10         Even #ChildrenThinkThat Trump is immature.           0.0\n",
      "11  RT @MIPooh: Trump Ag Dept @USDA Orders Hiding ...           0.0\n",
      "12  The Anti-Inauguration in a nutshell: we are of...           0.0\n",
      "13  RT @TeaPartyOrg: Trump Cracks the Electoral Co...           0.0\n",
      "14  #IGetDepressedWhen I have to inform the custom...           0.0\n",
      "15  RT @YoungDems4Trump: Show this to those who do...           0.0\n",
      "16  Trump chief won't reveal North Korea plan as t...           0.0\n",
      "17  RT @waynut1_0: If you're an employee of grub-h...           0.0\n",
      "18  RT @StatesPoll: Colorado: TRUMP vs Hillary vs ...           0.0\n",
      "19  #MAGA #NeverHillary #DrainTheSwamp https://t.c...           0.0\n"
     ]
    }
   ],
   "source": [
    "trumpData = trumpData.sort_values(by=['subjectivity'])\n",
    "trumpData = trumpData.reset_index(drop=True)\n",
    "print(trumpData.loc[0:19,['text','subjectivity']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tokenize Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clintonData['tokenized_sents'] = clintonData.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "trumpData['tokenized_sents'] = trumpData.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "bothData['tokenized_sents'] = bothData.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lemmatize Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "clintonData['text_lemmatized'] = clintonData.tokenized_sents.apply(lemmatize_text)\n",
    "trumpData['text_lemmatized'] = trumpData.tokenized_sents.apply(lemmatize_text)\n",
    "bothData['text_lemmatized'] = bothData.tokenized_sents.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Remove Stop Words From Tweets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        luvGodncountry : Wikileaks : Clinton Adviser T...\n",
       "1        VivaLaAmes : Holy CRAP , HILLARY HAS LOST IT !...\n",
       "2        amborin : We must ensure Hillary elected . She...\n",
       "3        Clinton say Trump ha ‘ degrading , insulting a...\n",
       "4        ElianaBenador : Exclusive — Trumpocrats Demand...\n",
       "5        JaredWyand : You disgusting HillaryClinton . T...\n",
       "6        1Kimsey : Crimsonmile RichardGrenell tamaragit...\n",
       "7        pmbasse : Team Hillary Gave GOP Establishment ...\n",
       "8        Harlan : Hillary running nasty , divisive camp...\n",
       "9        OzzeeLady : BREAKING : Federal Judge Gives Hil...\n",
       "10       LindaSuhler : But TRUMP unfit ? From worst POT...\n",
       "11       ajenable : Embrace power , friend . Hillary Do...\n",
       "12       trumpology : It 's outrageous . They keep dump...\n",
       "13       LouDobbs : Irony , Anyone ? `` Sometimes Bill ...\n",
       "14       jenncox24 : RacySicilian magnifier661 HillaryC...\n",
       "15       NolteNC : Trump end Birtherism Hillary birthed...\n",
       "16       lesliermyers : GOP created Trump disgusting li...\n",
       "17       dsrtime : What world ! ! SHOCKING ! ! ! PROOF ...\n",
       "18       iKaitg16 : SHOCKING ! ! ! PROOF That Hillary C...\n",
       "19       LouDobbs : LATimes poll realDonaldTrump Up 1 D...\n",
       "20       MathewSHarrison : Dear HillaryClinton # msm ha...\n",
       "21       May_Stone121 : HillaryClinton Hey Hillary - Yo...\n",
       "22       AmericanVoterUS : Hillary 's EVIL way may help...\n",
       "23       dalerogersL2528 : Nigel Farage : Hillary Clint...\n",
       "24       GaetaSusan : DIA E-Mails↔ISIS Deliberately Arm...\n",
       "25       Giuliani : `` Hillary Clinton wa one began unr...\n",
       "26       patrioticpepe : mike_pence LYING CLINTON IS SO...\n",
       "27       stephenstephan : Hillary Clinton , tell dreadf...\n",
       "28       mtracey : Another insane , baseless proclamati...\n",
       "29       BigStick2013 : Obama/Hillary doubled debt & am...\n",
       "                               ...                        \n",
       "25525    Veteran4Trump : Hillary Clinton 's Best Friend...\n",
       "25526    Happy # WomensEqualityDay HillaryClinton ! : /...\n",
       "25527    silenceconsent : Chelsea proud mamma HillaryCl...\n",
       "25528    Best Hillary Clinton bullshit # DemDebate # de...\n",
       "25529    TwitchyTeam : Watch : D ’ OH ! Hillary Clinton...\n",
       "25530    For realDonaldTrump continue one HillaryClinto...\n",
       "25531    good morning ! 's ! today 's day MAKE AMERICA ...\n",
       "25532    Chance got legendary Sodapoppintv # ThingsMore...\n",
       "25533    This woman perfect candidate Prison ! Do n't l...\n",
       "25534    March_for_Trump : # Florida Goes # Trump # FtL...\n",
       "25535    texasman2008 : `` Judge Jeanine : Hillary ‘ Po...\n",
       "25536    # NationalTellAJokeDay Hillary qualified POTUS...\n",
       "25537    GREAT VIDEO= & gt ; St. Louis Sisters Trump Sl...\n",
       "25538    shaneriderMA : . HillaryClinton Probably best ...\n",
       "25539          Chelsea Clinton 's best line DNC # politics\n",
       "25540    March_for_Trump : # Florida Goes # Trump # FtL...\n",
       "25541    TennConserv : Trump 's Campaign : To Make Amer...\n",
       "25542    If 're patriot , voting Hillary best way prove...\n",
       "25543    VickyBrush : Obama said best ha stuck . # Neve...\n",
       "25544    America_1st_ : This huge ! ! ! # HackingHillar...\n",
       "25545    LOL Idlers Hillary 's campaign n't even know u...\n",
       "25546    2ysur2ysub : And HillaryClinton realDonaldTrum...\n",
       "25547    UpTheRiverJBPD3 : : //t.co/ycuaNa3J7p I LOVE I...\n",
       "25548    asamjulian : mitchellvii This wa Hillary ’ pre...\n",
       "25549    Our country deserves best leader ! I ask think...\n",
       "25550    HillaryClinton : Happy Election Day ! : //t.co...\n",
       "25551    eilperin : `` Bernie Sanders would legendary n...\n",
       "25552    zIegend : hillary : know whats good ? donald :...\n",
       "25553    MAKE AMERICA GREAT AGAIN ! Obama 're fired ! #...\n",
       "25554    robynanne : Best # HRC # hrc2016 # ClintonScan...\n",
       "Name: processed, Length: 25555, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "custom_stopwords = ['RT','https','http','@',':']\n",
    "stop.extend(custom_stopwords)\n",
    "\n",
    "clintonData['without_stopwords'] = clintonData.text_lemmatized.apply(lambda x: [item for item in x if item not in stop])\n",
    "trumpData['without_stopwords'] = trumpData.text_lemmatized.apply(lambda x: [item for item in x if item not in stop])\n",
    "bothData['without_stopwords'] = bothData.text_lemmatized.apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Join tokens back together</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clintonData['processed'] = clintonData.without_stopwords.apply(lambda x: ' '.join(word for word in x))\n",
    "trumpData['processed'] = trumpData.without_stopwords.apply(lambda x: ' '.join(word for word in x))\n",
    "bothData['processed'] = bothData.without_stopwords.apply(lambda x: ' '.join(word for word in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add polarity and subjectivity columns to dataframes\n",
    "clintonData['polarity_2'] = clintonData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "clintonData['subjectivity_2'] = clintonData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "trumpData['polarity_2'] = trumpData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "trumpData['subjectivity_2'] = trumpData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "bothData['polarity_2'] = bothData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "bothData['subjectivity_2'] = bothData['processed'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
    "\n",
    "\n",
    "df_C2 = clintonData.groupby('created_str').mean()\n",
    "df_T2 = trumpData.groupby('created_str').mean()\n",
    "df_B2 = bothData.groupby('created_str').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dates back into column instead of being an index\n",
    "df_C2.to_csv('csv/clinton_2.csv', sep=',')\n",
    "df_C2 = pd.read_csv('csv/clinton_2.csv')\n",
    "\n",
    "df_T2.to_csv('csv/trump_2.csv', sep=',')\n",
    "df_T2 = pd.read_csv('csv/trump_2.csv')\n",
    "\n",
    "df_B2.to_csv('csv/both_2.csv', sep=',')\n",
    "df_B2 = pd.read_csv('csv/both_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_style = Style(colors=('red','blue','purple'))\n",
    "date_chart = pygal.Line(x_label_rotation=60, fill=False, style=custom_style)\n",
    "date_chart.title = 'Polarity Over Time'\n",
    "date_chart.x_labels = df_C2['created_str']\n",
    "date_chart.add(\"trump\", df_T2['polarity_2'])\n",
    "date_chart.add(\"Clinton\", df_C2['polarity_2'])\n",
    "date_chart.add(\"Both\", df_B2['polarity_2'])\n",
    "date_chart.render_to_file('images/polarity_date_processed.svg')\n",
    "\n",
    "date_chart = pygal.Line(x_label_rotation=60, fill=False, style=custom_style)\n",
    "date_chart.title = 'Subjectivity Over Time'\n",
    "date_chart.x_labels = df_C2['created_str']\n",
    "date_chart.add(\"trump\", df_T2['subjectivity_2'])\n",
    "date_chart.add(\"Clinton\", df_C2['subjectivity_2'])\n",
    "date_chart.add(\"Both\", df_B2['subjectivity_2'])\n",
    "date_chart.render_to_file('images/subjectivity_date_processed.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
